from collections import Counter
from sklearn.feature_extraction.text import CountVectorizer
import os
import pandas as pd
import time
from sklearn.cluster import KMeans
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from matplotlib import rcParams

# ‚úÖ –£–∫–∞–∑—ã–≤–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
file_path = "output/processed_tags.csv"

# ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª processed_tags.csv
if not os.path.exists(file_path):
    print(f"‚ö† –§–∞–π–ª '{file_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π...")

    try:
        tags_df = pd.read_csv("output/cleaned_tags.csv", encoding="utf-8")
        movies_df = pd.read_csv("output/cleaned_movies.csv", encoding="utf-8")
    except FileNotFoundError:
        print("‚ùå –û—à–∏–±–∫–∞: –û–¥–∏–Ω –∏–∑ —Ñ–∞–π–ª–æ–≤ ('cleaned_tags.csv' –∏–ª–∏ 'cleaned_movies.csv') –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        exit(1)

    processed_tags_df = tags_df.merge(movies_df, on="movieId", how="left")
    processed_tags_df.to_csv(file_path, index=False, encoding="utf-8")

    print(f"‚úÖ –§–∞–π–ª '{file_path}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
else:
    print(f"‚úÖ –§–∞–π–ª '{file_path}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ.")

# ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º processed_tags.csv
print(f"üîç –ó–∞–≥—Ä—É–∂–∞–µ–º {file_path}...")
try:
    tags_with_genres_df = pd.read_csv(file_path, encoding="utf-8")
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ! –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {tags_with_genres_df.shape}")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ '{file_path}': {e}")
    exit(1)

# ‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à—Ä–∏—Ñ—Ç–æ–≤ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
rcParams["font.family"] = "Arial"
rcParams["axes.unicode_minus"] = False


def analyze_clusters(tags_with_genres_df, n_clusters=10):
    """–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–≥–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º."""
    print("\n[–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤] –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–≥–æ–≤...")
    start_time = time.time()

    if tags_with_genres_df is None or tags_with_genres_df.empty:
        print("‚ùå –û—à–∏–±–∫–∞: tags_with_genres_df –ø—É—Å—Ç –∏–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω!")
        return

    # ‚úÖ –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    tags_with_genres_df['tag'] = tags_with_genres_df['tag'].fillna('')

    # ‚úÖ –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫
    tags_with_genres_df['tag'] = tags_with_genres_df['tag'].fillna('')

    # ‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–≥–æ–≤ –≤ —á–∏—Å–ª–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä–∞
    print("[–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤] –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–≥–∏ –≤ —á–∏—Å–ª–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä–∞...")

    vectorizer = CountVectorizer(tokenizer=lambda x: x.split('|'), max_features=500)
    tag_matrix = vectorizer.fit_transform(tags_with_genres_df['tag'])

    # ‚úÖ –°–æ–∑–¥–∞—ë–º DataFrame —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏
    tags_encoded_df = pd.DataFrame(tag_matrix.toarray(), columns=vectorizer.get_feature_names_out())

    # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–≥–∏ –∫ `tags_with_genres_df`
    tags_with_genres_df = pd.concat([tags_with_genres_df, tags_encoded_df], axis=1)

    print(f"[–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤] –¢–µ–≥–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã. –ù–æ–≤–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: {tags_with_genres_df.shape}")
    # ‚úÖ –£–¥–∞–ª—è–µ–º –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø–µ—Ä–µ–¥ KMeans
    features = tags_with_genres_df.drop(columns=['movieId', 'tag', 'title'], errors='ignore')

    # ‚úÖ –ó–∞–ø—É—Å–∫–∞–µ–º KMeans-–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
    print("[–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤] –ó–∞–ø—É—Å–∫–∞–µ–º KMeans-–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é...")
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    tags_with_genres_df['cluster'] = kmeans.fit_predict(features)

    print("[–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤] –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

    # ‚úÖ –ê–Ω–∞–ª–∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–≥–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
    print("[–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤] –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–≥–∏ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ...")
    popular_tags_data = []

    for cluster in tags_with_genres_df['cluster'].unique():
        cluster_tags = tags_with_genres_df[tags_with_genres_df['cluster'] == cluster]['tag'].dropna().astype(str)
        all_tags = ' '.join(cluster_tags)
        tag_counts = Counter(all_tags.split('|'))

        for tag, count in tag_counts.items():
            popular_tags_data.append({'cluster': cluster, 'tag': tag, 'count': count})

    popular_tags_df = pd.DataFrame(popular_tags_data)
    print("[–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤] –ê–Ω–∞–ª–∏–∑ —Ç–µ–≥–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω!")

    # ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    output_dir = './output'
    os.makedirs(output_dir, exist_ok=True)

    print("üìå [–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤] –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–≥–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º...")
    plt.figure(figsize=(12, 8))
    for cluster in popular_tags_df['cluster'].unique():
        cluster_data = popular_tags_df[popular_tags_df['cluster'] == cluster]
        plt.bar(cluster_data['tag'], cluster_data['count'], label=f'Cluster {cluster}')

    plt.xticks(rotation=90, fontsize=10)
    plt.xlabel('Tag', fontsize=12)
    plt.ylabel('Count', fontsize=12)
    plt.title('Tag Distribution by Cluster', fontsize=14)
    plt.legend()
    plt.tight_layout(pad=4.0)

    output_file = os.path.join(output_dir, 'tag_distribution_by_cluster.png')
    plt.savefig(output_file, format='png')
    plt.close()
    print(f"[–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤] –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_file}")

    print(f"[–ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤] –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {time.time() - start_time:.2f} —Å–µ–∫—É–Ω–¥\n")


def analyze_genres_and_clusters(movies_file="output/cleaned_movies.csv",
                                tags_file="output/processed_tags.csv",
                                n_clusters=10):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∂–∞–Ω—Ä–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º."""
    print("[–ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤] –ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º...")
    start_time = time.time()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    movies_df = pd.read_csv(movies_file, encoding="utf-8")
    tags_df = pd.read_csv(tags_file, encoding="utf-8")

    # One-hot encoding –∂–∞–Ω—Ä–æ–≤
    print("[–ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤] –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∂–∞–Ω—Ä—ã –≤ one-hot —Ñ–æ—Ä–º–∞—Ç...")
    mlb = MultiLabelBinarizer()
    movies_df["genres"] = movies_df["genres"].apply(lambda x: x.split("|") if isinstance(x, str) else [])
    genres_matrix = mlb.fit_transform(movies_df["genres"])
    genres_df = pd.DataFrame(genres_matrix, columns=mlb.classes_, index=movies_df["movieId"])

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–µ–≥–∞–º –∏ –∂–∞–Ω—Ä–∞–º
    print("[–ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤] –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ...")
    tags_with_genres_df = pd.merge(tags_df, movies_df[["movieId"]], on="movieId", how="left")
    tags_with_genres_df = pd.merge(tags_with_genres_df, genres_df, on="movieId", how="left")

    # PCA –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
    print("[–ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤] –ü—Ä–∏–º–µ–Ω—è–µ–º PCA –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏...")
    pca = PCA(n_components=min(38, tags_with_genres_df.shape[1] - 2), random_state=42)
    features_pca = pca.fit_transform(tags_with_genres_df.iloc[:, 3:])  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏

    # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è KMeans
    print("[–ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤] –ó–∞–ø—É—Å–∫–∞–µ–º KMeans-–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é...")
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    tags_with_genres_df["cluster"] = kmeans.fit_predict(features_pca)

    print("[–ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤] –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

    # –ê–Ω–∞–ª–∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Ç–µ–≥–æ–≤
    print("[–ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤] –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–≥–∏ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Ç–µ—Ä–µ...")
    popular_tags_data = []
    for cluster in range(n_clusters):
        cluster_tags = tags_with_genres_df[tags_with_genres_df["cluster"] == cluster]["tag"].dropna()
        all_tags = " ".join(cluster_tags.astype(str))
        tag_counts = Counter(all_tags.split("|"))

        for tag, count in tag_counts.items():
            popular_tags_data.append({"cluster": cluster, "tag": tag, "count": count})

    popular_tags_df = pd.DataFrame(popular_tags_data)

    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)

    plt.figure(figsize=(12, 8))
    for cluster in popular_tags_df["cluster"].unique():
        cluster_data = popular_tags_df[popular_tags_df["cluster"] == cluster]
        plt.bar(cluster_data["tag"], cluster_data["count"], label=f"Cluster {cluster}")

    plt.xticks(rotation=90)
    plt.xlabel("Tag")
    plt.ylabel("Count")
    plt.title("Tag Distribution by Cluster (with Genres)")
    plt.legend()
    plt.tight_layout()

    output_file = os.path.join(output_dir, "tag_distribution_by_cluster_with_genres.png")
    plt.savefig(output_file)
    plt.close()
    print(f"[–ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤] –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_file}")
    print(f"[–ê–Ω–∞–ª–∏–∑ –∂–∞–Ω—Ä–æ–≤] –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {time.time() - start_time:.2f} —Å–µ–∫—É–Ω–¥\n")


# –£–∫–∞–∑—ã–≤–∞–µ–º, –∫–∞–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å
__all__ = ["analyze_clusters", "analyze_genres_and_clusters"]